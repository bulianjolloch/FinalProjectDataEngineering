apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate  # <--- Changed from Workflow
metadata:
  name: ml-workflow-template # <--- Fixed name so Sensor can find it
  namespace: argo-workflows
spec:
  entrypoint: pipeline
  serviceAccountName: argo-workflow

  # These default values are used unless the Sensor overrides them
  arguments:
    parameters:
      # The Sensor will overwrite this value with the uploaded filename
      - name: filename 
        value: "StudentsPerformance.csv" 
      - name: bucket-name
        value: "input-data"
      - name: experiment-name-mlflow
        value: "argo-event-run"
      - name: output-path
        value: "data/processed/"
      - name: test-size
        value: "0.2"
      - name: random-state
        value: "187"
      - name: max-relative-error
        value: "10.0"
      - name: p95-relative-error
        value: "1.0"
      - name: mae-drift-factor
        value: "1.2"
      - name: max-mean-residual
        value: "5.0"

  templates:
  - name: pipeline
    steps:
      - - name: eda
          template: run-script
          arguments:
            parameters:
              - name: script
                value: exploratory_data_analysis.py
              - name: cli-args
                # Removed --experiment-name-mlflow from here
                value: >-
                  --bucket-name {{workflow.parameters.bucket-name}}
                  --filename {{workflow.parameters.filename}}

      - - name: preprocess
          template: preprocess-step
          arguments:
            parameters:
              - name: script
                value: preprocessing.py
              - name: cli-args
                value: >-
                  --bucket-name {{workflow.parameters.bucket-name}}
                  --filename {{workflow.parameters.filename}}
                  --output-path {{workflow.parameters.output-path}}
                  --test-size {{workflow.parameters.test-size}}
                  --random-state {{workflow.parameters.random-state}}

      - - name: train
          template: train-step
          arguments:
            parameters:
              - name: script
                value: train.py
              - name: cli-args
                value: >-
                  --preprocessing-run-id {{steps.preprocess.outputs.parameters.preprocessing-run-id}}

      - - name: evaluate
          template: run-script
          arguments:
            parameters:
              - name: script
                value: evaluation.py
              - name: cli-args
                value: >-
                  --training-run-id {{steps.train.outputs.parameters.training-run-id}}
                  --preprocessing-run-id {{steps.preprocess.outputs.parameters.preprocessing-run-id}}
                  --max-relative-error {{workflow.parameters.max-relative-error}}
                  --p95-relative-error {{workflow.parameters.p95-relative-error}}
                  --mae-drift-factor {{workflow.parameters.mae-drift-factor}}
                  --max-mean-residual {{workflow.parameters.max-mean-residual}}

  - name: run-script
    inputs:
      parameters:
        - name: script
        - name: cli-args
    container:
      image: ghcr.io/bulianjolloch/python-ml:1.0.14
      command: ["bash", "-c"]
      args:
        - >
          python {{inputs.parameters.script}} {{inputs.parameters.cli-args}}
      env:
        # Added this block to pass experiment name correctly
        - name: MLFLOW_EXPERIMENT_NAME
          value: "{{workflow.parameters.experiment-name-mlflow}}"
          
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-argo-workflows
              key: accesskey  # Updated key name to match ExternalSecrets

        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-argo-workflows
              key: secretkey # Updated key name to match ExternalSecrets

        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-admin
              key: postgres-user

        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-admin
              key: postgres-password

        - name: MLFLOW_S3_ENDPOINT_URL
          value: "http://minio.data-storage.svc.cluster.local:9000"

        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow.mlops.svc.cluster.local:5000"

  # ... (Repeat the Env block update for preprocess-step and train-step templates as well) ...
  # For brevity, verify preprocess-step and train-step also have the MLFLOW_EXPERIMENT_NAME env var.

  - name: preprocess-step
    inputs:
      parameters:
        - name: script
        - name: cli-args
    container:
      image: ghcr.io/bulianjolloch/python-ml:1.0.14
      command: ["bash", "-c"]
      args:
        - >
          python {{inputs.parameters.script}} {{inputs.parameters.cli-args}}
      env:
        - name: MLFLOW_EXPERIMENT_NAME
          value: "{{workflow.parameters.experiment-name-mlflow}}"
        # ... (rest of standard env vars) ...
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-argo-workflows
              key: accesskey
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-argo-workflows
              key: secretkey
        # ... (rest of postgres env vars) ...
        - name: MLFLOW_S3_ENDPOINT_URL
          value: "http://minio.data-storage.svc.cluster.local:9000"
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow.mlops.svc.cluster.local:5000"
    outputs:
      parameters:
        - name: preprocessing-run-id
          valueFrom:
            path: /tmp/preprocessing_run_id.txt

  - name: train-step
    inputs:
      parameters:
        - name: script
        - name: cli-args
    container:
      image: ghcr.io/bulianjolloch/python-ml:1.0.14
      command: ["bash", "-c"]
      args:
        - >
          python {{inputs.parameters.script}} {{inputs.parameters.cli-args}}
      env:
        - name: MLFLOW_EXPERIMENT_NAME
          value: "{{workflow.parameters.experiment-name-mlflow}}"
        # ... (rest of standard env vars) ...
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-argo-workflows
              key: accesskey
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-argo-workflows
              key: secretkey
        # ... (rest of postgres env vars) ...
        - name: MLFLOW_S3_ENDPOINT_URL
          value: "http://minio.data-storage.svc.cluster.local:9000"
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow.mlops.svc.cluster.local:5000"
    outputs:
      parameters:
        - name: training-run-id
          valueFrom:
            path: /tmp/train_run_id.txt